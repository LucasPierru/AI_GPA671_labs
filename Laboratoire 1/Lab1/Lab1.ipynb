{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:8pt\">*ÉTS Montréal, GPA671 : Introduction à l’intelligence artificielle. Date : le 08/08/21. Auteur : Jérôme Rony. Version : 1.1*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFMiQNy6BCfW"
   },
   "source": [
    "# Laboratoire 1 : Caractéristiques de performance et Réseaux de Neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Courbe ROC\n",
    "\n",
    "### Rappels de cours \n",
    "\n",
    "Dans une courbe ROC, l'axe des ordonnées correspond au rappel (ou *recall*) et l'axe des abscisses correspond au taux de faux positifs (*False Positive Rate* ou *FPR*). Chaque point de la courbe correspond aux valeurs de rappel et FPR pour un seuil différent. Pour tracer une courbe correcte, il faut donc prendre un grand nombre de seuils, ou, idéalement, prendre tous les seuils possibles.\n",
    "\n",
    "<img src=\"images/roc.png\"  height=\"150\" width=\"200\">\n",
    "\n",
    "On définit les *True Positive* (*TP*), *False Positive* (*FP*), *True Negative* (*TN*) et *False Negative* (*FN*) comme suit:\n",
    "\n",
    "<img src=\"images/confusion_matrix.png\"  height=\"150\" width=\"200\">\n",
    "\n",
    "Le rappel a pour formule:\n",
    "\\begin{equation*}\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "\\end{equation*}\n",
    "\n",
    "Le taux de faux positifs a pour formule:\n",
    "\\begin{equation*}\n",
    "FPR = \\frac{FP}{FP +TN}\n",
    "\\end{equation*}\n",
    "\n",
    "### Questions\n",
    "\n",
    "Dans cet exercice, on cherche à caractériser les performances de différents détecteurs à l'aide d'une courbe ROC (puis PR dans l'exercice 2). On fournit les fichiers qui correspondent aux détections faites par ces détecteurs. Les fichiers ont pour format `probabilité étiquette` où probabilité est la probabilité prédite par le détecteur que l'étiquette soit 1. Un détecteur parfait produirait donc des probabilités égales aux étiquettes.\n",
    "\n",
    "1. Lire tous les fichiers présents dans le dossier `detection_files`. Il est conseillé d'utiliser le paquet `glob` de la bibliothèque standard de Python pour trouver les fichiers, plutôt que d'écrire leurs noms explicitement dans le code.\n",
    "2. Pour chaque seuil parmi $\\{0.1, 0.5, 0.7\\}$ compter le nombre de TP, FP, TN et FN. Enfin, calculer le Rappel et le FPR correspondant.\n",
    "3. Calculer les valeurs de rappel et FPR pour tous les seuils possibles pour chaque détecteur. Stocker les valeurs obtenues dans un dictionnaire.\n",
    "4. Pour chaque détecteur, calculer la valeur de l'aire sous la courbe (*Area Under Curve* ou *AUC*). Commenter la méthode utilisée pour calculer l'aire et l'impact du choix de cette méthode sur l'indicateur de performance obtenu.\n",
    "5. Dans un même graphique, tracer les courbes ROC correspondant à chaque détecteur. Chaque courbe doit avoir une couleur différente. Indiquer aussi la valeur de l'AUC dans la légende.\n",
    "5. Expliquer pourquoi le taux FPR n'est pas très indicatif dans ce cas de classification.\n",
    "\n",
    "> Afin de vérifier vos résultats, vous pouvez utiliser sklearn metrics ([ROC Curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) et [ROC AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)) mais vous ne pouvez pas l'utiliser pour faire l'exercice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Courbe PR\n",
    "\n",
    "### Rappels de cours\n",
    "\n",
    "Comme son nom l'indique, la courbe Précision-Rappel a pour axe des abscisses le rappel et pour axe des ordonnées la précision :\n",
    "\n",
    "<img src=\"images/pr.png\"  height=\"200\" width=\"250\">\n",
    "\n",
    "\n",
    "La précision a pour formule :\n",
    "\\begin{equation*}\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "\\end{equation*}\n",
    "\n",
    "### Questions\n",
    "\n",
    "1. Lire tous les fichiers présents dans le dossier `detection_files`. Il est conseillé d'utiliser le paquet `glob` de la bibliothèque standard de Python pour trouver les fichiers, plutôt que d'écrire leurs noms explicitement dans le code.\n",
    "2. Pour chaque seuil parmi $\\{0.1, 0.5, 0.7\\}$ compter le nombre de TP, FP, TN et FN et calculer la Précision et le Rappel correspondant.\n",
    "3. Calculer les valeurs de Précision et Rappel pour tous les seuils possibles pour chaque détecteur. Stocker les valeurs obtenues dans un dictionnaire.\n",
    "4. Pour chaque détecteur, calculer la valeur de l'aire sous la courbe (aussi appelée *Average Precision* pour la courbe PR ou *AUPR*).\n",
    "5. Dans un même graphique, tracer les courbes PR correspondant à chaque détecteur. Chaque courbe doit avoir une couleur différente. Indiquer aussi la valeur de l'AUPR dans la légende.\n",
    "6. Expliquer pourquoi la courbe Précision-Rappel est plus adaptée pour mesurer les performances.\n",
    "\n",
    "> Afin de vérifier vos résultats, vous pouvez utiliser sklearn metrics ([PR Curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html) et [Average Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html))  mais vous ne pouvez pas l'utiliser pour faire l'exercice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Perceptron\n",
    "\n",
    "### Rappels de cours \n",
    "\n",
    "Le perceptron est le plus simple des réseaux de neurones avec un vecteur d'entrée ${\\bf x}_i$ et une seule sortie $y_i$. Ici, $i$ représente l'indice de l'exemple dans le jeu de données. La sortie est calculée comme une somme pondérée par un vecteur de poids $\\bf w$ des valeurs d'entrée (avec un biais contenu dans $\\bf w$) à laquelle est appliquée une fonction d'activation $F$. Pendant l'entrainement on va évaluer chaque exemple et on change le vecteur de pois $\\bf w$ afin de minimiser l'erreur. Pour plus de détails voir le cours 3.\n",
    "\n",
    "Étant donné un exemple ${\\bf x} \\in \\mathbb{R}^n$ (dans l'exercice, $n=2$), la sortie $y$ est calculée comme suit :\n",
    "\\begin{equation*}\n",
    "y_i = F(\\text{net}_i) = F(\\underbrace{{\\bf w}^\\intercal{\\bf x}_i}_{\\in \\mathbb{R}})\n",
    "\\end{equation*}\n",
    "\n",
    "On définit la fonction de coût comme suit:\n",
    "\\begin{equation*}\n",
    "E = \\frac{1}{2} (y_i - d_i)^2\n",
    "\\end{equation*}\n",
    "avec $d_i$ qui est la réponse désirée pour l'exemple ${\\bf x}_i$, fournie dans le jeu de données.\n",
    "\n",
    "Le gradient de la fonction de coût par rapport aux poids est calculé comme :\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\bf w} E = \\dfrac{\\partial E}{\\partial y_i} \\dfrac{\\partial y_i}{\\partial \\text{net}_i} \\dfrac{\\partial \\text{net}_i}{\\partial {\\bf w}} = (y_i - d_i) F'(\\text{net}_i) {\\bf x}\n",
    "\\end{equation*}\n",
    "\n",
    "On définit alors la fonction de mise à jour des poids:\n",
    "\\begin{equation*}\n",
    "\\textbf{w} = \\textbf{w} - \\eta { \\nabla_{\\textbf{w}} E}\n",
    "\\end{equation*}\n",
    "avec $\\eta$ la constante d'apprentissage.\n",
    "\n",
    "On utilise la sigmoïde comme fonction d'activation:\n",
    "\\begin{equation*}\n",
    "F(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\end{equation*}\n",
    "\n",
    "La dérivée de la fonction sigmoïde est:\n",
    "\\begin{equation*}\n",
    "F'(x) = F(x) (1 - F(x))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Charger le fichier `lab1_1.npz` avec la fonction `np.load`. Les données sont sous forme de dictionnaire dont les clés peuvent être trouvées avec `list(data.keys())`.\n",
    "2. Dans un graphique, à l’aide de la fonction `scatter`, afficher ces données. Utiliser des marqueurs différents pour les différentes classes ainsi qu'une légende.\n",
    "3. Les poids du réseau sont initialisés à ${\\bf w}^\\intercal = [{\\bf w}_0, {\\bf w}_1, {\\bf w}_2] = [0, −1, −1]$. ${\\bf w}_0$ correspond au biais et est associé au seuil de décision. Afficher les données et la frontière de décision correspondant à ces poids dans un graphique.\n",
    "\n",
    "> La frontière de décision est définie par l’équation suivante (ici, $x$ et $y$ ne représentent pas les données, mais les axes du plan) :\n",
    "\\begin{equation*}\n",
    "y = \\frac{-{\\bf w}_1}{{\\bf w}_2} x - \\frac{{\\bf w}_0}{{\\bf w}_2}\n",
    "\\end{equation*}\n",
    "\n",
    "4. Implémenter la propagation directe dans la méthode `forward` du Perceptron avec la classe fournie ci-dessous. Calculer le taux d'exactitude avec les poids initiaux en utilisant la fonction `forward`. Commenter ce taux d'exactitude par rapport à la figure générée précédemment. Que faut-il ajouter dans le graphique pour correctement représenter la frontière de décision?\n",
    "5. Implémenter la mise à jour des poids dans la méthode `update`. Pour cet exercice, la fonction `update` ne renvoie rien. Effectuer un ajustement des poids en utilisant le premier exemple et $\\eta$ = 0.01. Dans le rapport, détailler les calculs pour cette étape.\n",
    "6. Afficher dans un graphique, les données, la frontière de décision initiale ainsi que la nouvelle frontière.\n",
    "7. Continuer l’apprentissage en faisant 100 itérations sur l'ensemble les données. Tracer l’évolution du taux d'exactitude avec chaque ajustement. Commenter la courbe.\n",
    "8. Afficher dans un graphique, les données et frontière de décision finale.\n",
    "9. Comment se termine l’apprentissage. Est-ce que l’algorithme converge ? Expliquer pourquoi. Commenter le taux d'exactitude de la solution finale.\n",
    "10. Que se passerait-il si on changeait l’ordre de présentation des données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0z5PWeJWWUT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, lr: float):\n",
    "        \"\"\"\n",
    "        Constructeur de la classe Perceptron.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : float\n",
    "            Taux d'apprentissage pour la mise à jour des poids.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.w = np.array([0, -1, -1], dtype=np.float) # vecteur de poids   \n",
    "        self.lr = lr\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.float:\n",
    "        \"\"\"\n",
    "        Propagation directe du perceptron avec sa fonction d'activation $y = F(w^T x)$.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Vecteur d'entrée de longueur 2.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y : np.float\n",
    "            Sortie du perceptron après la fonction d'activation.\n",
    "        \n",
    "        \"\"\"\n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide\n",
    "    \n",
    "    def update(self, x: np.ndarray, grad_output: np.float) -> None:\n",
    "        \"\"\"\n",
    "        Mise à jour des poids w.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Vecteur d'entrée de longueur 2.\n",
    "        grad_output : np.float\n",
    "            Gradient de l'erreur par rapport à la sortie y perceptron $\\nabla_y E$.\n",
    "\n",
    "        \"\"\"\n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qI_N-cWhWlcb"
   },
   "source": [
    "## Exercice 4 : Généralisation du Perceptron\n",
    "\n",
    "Dans cet exercice, on va généraliser le code précédent afin de pouvoir évaluer plusieurs exemples en même temps (c’est-à-dire vectoriser le code) et obtenir plus sorties en même temps (donc avoir une couche générale).\n",
    "\n",
    "La sortie ${\\bf Y}$ du perceptron est calculée comme:\n",
    "\\begin{equation}\n",
    "{\\bf Y} = F(\\textbf{NET}) = F({\\bf W} {\\bf X})\n",
    "\\end{equation}\n",
    "avec $\\bf X$ qui est la matrice d'entrées de taille (# entrées, # exemples),\n",
    "$\\bf Y$ qui est la matrice de sorties de taille (# sorties, # exemples) et \n",
    "$\\bf W$ qui est la matrice de poids **avec biais** de taille (# sorties, # entrées + 1). Cette fois, on intialise cette matrice de manière aléatoire selon l'initialisation de Glorot & Bengio (2010).\n",
    "\n",
    "On définit la fonction de coût pour un exemple comme suit :\n",
    "\\begin{equation*}\n",
    "E = \\frac{1}{2} \\sum_i ||{\\bf Y}_i - {\\bf D}_i||^2_2\n",
    "\\end{equation*}\n",
    "avec ${\\bf Y}$ le vecteur des sorties obtenues pour ${\\bf X}$ et ${\\bf D}$ le vecteur des réponses désirées pour ${\\bf x}$.\n",
    "\n",
    "Pour calculer le gradient de la fonction de coût par rapport à $\\bf Y$:\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\bf Y} E = {\\bf Y} - {\\bf D}\n",
    "\\end{equation*}\n",
    "\n",
    "Ainsi, le gradient de la fonction de coût par rapport à $\\bf NET$ est:\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\bf NET} E = \\nabla_{\\bf Y} E \\odot F'({\\bf NET})\n",
    "\\end{equation*}\n",
    "avec $\\odot$ le produit élément par élément.\n",
    "\n",
    "Grâce à la règle de dérivation des fonctions composées:\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\bf W} E = \\nabla_{\\bf NET} E \\; {\\bf X}^\\top\n",
    "\\end{equation*}\n",
    "\n",
    "On définit alors la fonction de mise à jour des poids:\n",
    "\\begin{equation*}\n",
    "{\\bf W} = {\\bf W} - \\eta \\nabla_{\\bf W} E\n",
    "\\end{equation*}\n",
    "avec $\\eta$ la constante d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Dans cet exercice, nous allons utiliser les données contenues dans le fichier `lab1_2.npz`. Charger ces données et les afficher avec des marqueurs différents pour les différentes classes ainsi qu'une légende.\n",
    "2. Implémenter la propagation directe dans la méthode `forward` de Layer avec la classe fournie ci-dessous. Calculer le taux d'exactitude avec les poids initiaux en utilisant la fonction `forward`.\n",
    "3. Implémenter la mise à jour des poids dans la méthode `update`. Pour cet exercice, la fonction `update` renvoie le gradient de l'erreur par rapport à l'entrée de la couche, ce qui permet de mettre plusieurs couches en série.\n",
    "\n",
    "> Indication : le gradient de l'erreur par rapport à l'entrée d'une couche doit avoir la même taille que l'entrée X de la couche.\n",
    "\n",
    "4. Afficher dans un graphique, les données, la frontière de décision initiale ainsi que la frontière de décision finale après un apprentissage complet. Tracer aussi l’évolution du taux d'exactitude avec chaque ajustement. \n",
    "5. Comment se termine l’apprentissage. Est-ce que l’algorithme converge ? Expliquer pourquoi. Commenter le taux d'exactitude de la solution finale.\n",
    "6. Que se passerait-il si on changeait l’ordre de présentation des données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sId2RvcEBCfc"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, n_in: int, n_out: int, lr: float):\n",
    "        \"\"\"\n",
    "        Constructeur de la classe Layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_int : int\n",
    "            Nombre d'entrées.\n",
    "        n_out : int\n",
    "            Nombre de sorties.\n",
    "        lr : float\n",
    "            Taux d'apprentissage pour la mise à jour des poids.\n",
    "        \n",
    "        \"\"\"\n",
    "        bound = (6 / (n_in + n_out)) ** 0.5  # initialisation selon Glorot & Bengio (2010)\n",
    "        # matrice de poids (+1 pour le biais)\n",
    "        self.W = np.random.uniform(low=-bound, high=bound, size=(n_out, n_in + 1)) \n",
    "        self.W[:, 0] = 0  # biais initialisé à 0\n",
    "        self.lr = lr\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Propagation directe de la couche avec sa fonction d'activation $Y = F(W^T X)$.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées. Taille : (n_in, # exemples).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y : np.ndarray\n",
    "            Sorties de la couche après la fonction d'activation. Taille : (n_out, # exemples)\n",
    "\n",
    "        \"\"\"\n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide\n",
    "        \n",
    "    def update(self, X: np.ndarray, grad_output: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Mise à jour des poids w et retourne le gradient de l'erreur par rapport à l'entrée de la couche $\\nabla_X E$.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées. Taille : (n_in, # exemples).\n",
    "        grad_output : np.ndarray.\n",
    "            Gradient de l'erreur par rapport à la sortie Y de la couche $\\nabla_Y E$. Taille : (n_out, # exemples)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        grad_input : np.ndarray\n",
    "            Gradient de l'erreur par rapport à l'entrée X de la couche $\\nabla_X E$. Taille : (n_in, # exemples)\n",
    "\n",
    "        \"\"\"\n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zjo6usVXBCfo"
   },
   "source": [
    "## Exercice 5 : Réseau de neurones multicouches\n",
    "\n",
    "Dans cet exercice, on implémente un réseau de neurones multicouches. Ce réseau va séquentiellement appliquer la propagation directe de ses couches successives. Pour la mise à jour des poids, il va appliquer la mise à jour des poids de chaque couche en \"remontant\" le réseau depuis la sortie.\n",
    "\n",
    "1. À l'aide de la classe Layer de l'exercice 4, implémenter un réseau de neurones à plusieurs couches (*Multi-Layer Perceptron* ou MLP). Créer un réseau avec une couche cachée et 2 neurones par couche à l'aide de la classe MLP et l'entrainer en affichant l'erreur et le taux d'exactitude au cours de l'entrainement.\n",
    "2. Essayer d'autres configurations de réseaux multicouches (e.g. ajouter des couches, augmenter le nombre de neurones par couche, etc.) et de paramètres d'entrainement (e.g. augmenter le taux d'apprentissage, faire plus d'itérations, etc.). Quel critère avez-vous utilisé pour arrêter valider l'entrainement ? Quel critère avez-vous utilisé pour comparer les différentes configurations ?\n",
    "3. Bonus : Afficher dans un même graphique les données d'entrée et la borne de décision du modèle multicouches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lL2UhTnKBCfq"
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, list_of_layers: list):\n",
    "        \"\"\"\n",
    "        Classe pour implémenter un réseau de neurones multicouches.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        list_of_layers : list\n",
    "            Liste ordonnée des couches successives du réseau de neurones.\n",
    "        \"\"\"\n",
    "        self.list_of_layers = list_of_layers\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Propagation directe à travers les couches du MLP.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y : np.ndarray\n",
    "            Sorties après propagation directe.\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def update(self, X: np.ndarray, grad_output: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Mise à jour des poids des couches successives du MLP. Renvoie le gradient de l'erreur par \n",
    "        rapport à l'entrée du MLP.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées.\n",
    "        grad_output : np.ndarray\n",
    "            Gradient de l'erreur par rapport à la sortie Y du MLP $\\nabla_Y E$.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        grad_input : np.ndarray\n",
    "            Gradient de l'erreur par rapport à l'entrée X de la couche $\\nabla_X E$.\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
