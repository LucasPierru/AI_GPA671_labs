{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 1 - GPA671 - Equipe 16 - Lucas Pierru PIEL14069708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les différentes librairies\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On lit les noms de fichiers\n",
    "files = glob.glob('detection_files/*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = [0.1, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On initialise les éléments de notre matrice de confusion et les rappels et FPR à 0\n",
    "TP = np.zeros((len(files),len(seuil)))\n",
    "TN = np.zeros((len(files),len(seuil)))\n",
    "FP = np.zeros((len(files),len(seuil)))\n",
    "FN = np.zeros((len(files),len(seuil)))\n",
    "Recall = np.zeros((len(files),len(seuil)))\n",
    "FPR = np.zeros((len(files),len(seuil)))\n",
    "\n",
    "for m in range (len(files)):\n",
    "    data = np.loadtxt(files[m])\n",
    "    for n in range (len(seuil)):   \n",
    "        for i in range (len(data)):\n",
    "            # On incrémente les valeurs de la matrice de confusion suivant leurs conditions respectives\n",
    "            if (data[i][0]>=seuil[n]) & (data[i][1] == 1):\n",
    "                TP[m][n] = TP[m][n] + 1\n",
    "            elif (data[i][0]<seuil[n]) & (data[i][1] == 0):\n",
    "                TN[m][n] = TN[m][n] + 1\n",
    "            elif (data[i][0]<seuil[n]) & (data[i][1] == 1):\n",
    "                FN[m][n] = FN[m][n] + 1\n",
    "            else:\n",
    "                FP[m][n] = FP[m][n] + 1\n",
    "\n",
    "        Recall[m][n] = (TP[m][n])/(TP[m][n]+FN[m][n])\n",
    "        FPR[m][n] = (FP[m][n])/(FP[m][n]+TN[m][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3, 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit le titre et les axes de notre graphique\n",
    "plt.title(\"ROC Curves\") \n",
    "plt.xlabel(\"FPR\") \n",
    "plt.ylabel(\"Recall\") \n",
    "\n",
    "# On définit les limites des axes\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# On initialise nos variables\n",
    "Recall = []\n",
    "FPR = []\n",
    "AUC = np.zeros(len(files))\n",
    "\n",
    "Rappel_d = {}\n",
    "FPR_d = {}\n",
    "a = {}\n",
    "\n",
    "for m in range (len(files)):\n",
    "    TP = []\n",
    "    TN = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    data = np.loadtxt(files[m])\n",
    "    seuils = np.unique(data[:,0]) # Nos seuils sont les valeurs uniques des detecteurs\n",
    "    \n",
    "    for n in range (len(seuils)):   \n",
    "            # On fait la somme des éléments de la matrice en fonction de notre seuil\n",
    "            \n",
    "            TP = np.append(TP,np.sum((([data[:,0]>=seuils[n]]) & (data[:,1] == 1))*1))\n",
    "            FP = np.append(FP,np.sum((([data[:,0]>=seuils[n]]) & (data[:,1] == 0))*1))\n",
    "            TN = np.append(TN,np.sum((([data[:,0]<seuils[n]]) & (data[:,1] == 0))*1))\n",
    "            FN = np.append(FN,np.sum((([data[:,0]<seuils[n]]) & (data[:,1] == 1))*1)) \n",
    "            \n",
    "            # Cette méthode nous evite une boucle et donc nous fait gagner beaucoup de temps\n",
    "    \n",
    "    Recall = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "    print (FP)\n",
    "    for z in range (len(Recall)):\n",
    "        if (z<len(Recall)-1):\n",
    "            # On fait le calcul de notre aire\n",
    "            \n",
    "            deltaR = Recall[z]\n",
    "            deltaFPR = FPR[z]-FPR[z+1]\n",
    "\n",
    "            AUC[m] = AUC[m] + deltaR*deltaFPR\n",
    "            \n",
    "            # On met les valeurs dans un dictionnaire\n",
    "            Rappel_file = 'Fichier_'+str(m+1)\n",
    "            Rappel_seuil = 'Seuil_'+str(z)\n",
    "            Rappel_id = 'Rappel_fichier_'+str(m+1)+'_seuil_'+str(z)\n",
    "            \n",
    "            Rappel_d[Rappel_file] = m+1\n",
    "            Rappel_d[Rappel_seuil] = z\n",
    "            Rappel_d[Rappel_id] = Recall[z]\n",
    "\n",
    "            FPR_file = 'Fichier_'+str(m+1)\n",
    "            FPR_seuil = 'Seuil_'+str(z)\n",
    "            FPR_id = 'FPR_fichier_'+str(m+1)+'_seuil_'+str(z)\n",
    "            \n",
    "            FPR_d[FPR_file] = m+1\n",
    "            FPR_d[FPR_seuil] = z\n",
    "            FPR_d[FPR_id] = FPR[z]\n",
    "\n",
    "    # On affiche les valeurs de AUC        \n",
    "    plt.plot(FPR, Recall,label=[round(AUC[m],4),files[m][16:]])\n",
    "    plt.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le calcul de l'aire, nous allons simplement utiliser la méthode des rectangles qui n'est pas la plus précise mais comme nous avons un grand nombre d'échantillons, nos rectangles ressemblerons plus à des lignes car la largeur sera très infime. On peut voir un exemple ci-dessous.\n",
    "\n",
    "<img src=\"CalculAire.jpg\">\n",
    "\n",
    "Notre calcul est donc de faire la somme des rectangles sous la courbe avec la hauteur correspondant à la valeur du rappel pour un seuil x et la largeur correspond à la différence du FPR au seuil x+1 et du FPR au seuil x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score = np.zeros(len(files))\n",
    "\n",
    "for y in range (len(files)):\n",
    "    data0 = np.loadtxt(files[y])\n",
    "\n",
    "    score[y] = roc_auc_score(data0[:,1],data0[:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le taux FPR n'est pas très indicatif car nous n'avons pas énormement de faux positifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Voir Q1 Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = [0.1, 0.5, 0.7]\n",
    "\n",
    "# On initialise nos variables avec une certaine taille pour nos matrice\n",
    "\n",
    "TP = np.zeros((len(files),len(seuil)))\n",
    "TN = np.zeros((len(files),len(seuil)))\n",
    "FP = np.zeros((len(files),len(seuil)))\n",
    "FN = np.zeros((len(files),len(seuil)))\n",
    "Recall = np.zeros((len(files),len(seuil)))\n",
    "Precision = np.zeros((len(files),len(seuil)))\n",
    "\n",
    "for m in range (len(files)):\n",
    "    data = np.loadtxt(files[m])\n",
    "    for n in range (len(seuil)):\n",
    "        \n",
    "        # On effectue le calcul de la matrice de confusion comme dans l'exercice 1\n",
    "        \n",
    "        for i in range (len(data)):\n",
    "            if (data[i][0]>=seuil[n]) & (data[i][1] == 1):\n",
    "                TP[m][n] = TP[m][n] + 1\n",
    "            elif (data[i][0]<seuil[n]) & (data[i][1] == 0):\n",
    "                TN[m][n] = TN[m][n] + 1\n",
    "            elif (data[i][0]<seuil[n]) & (data[i][1] == 1):\n",
    "                FN[m][n] = FN[m][n] + 1\n",
    "            else:\n",
    "                FP[m][n] = FP[m][n] + 1\n",
    "\n",
    "        Recall[m][n] = (TP[m][n])/(TP[m][n]+FN[m][n])\n",
    "        Precision[m][n] = (TP[m][n])/(TP[m][n]+FP[m][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3, 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"ROC Curves\") \n",
    "plt.xlabel(\"Recall\") \n",
    "plt.ylabel(\"Precision\") \n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "Recall = []\n",
    "Precision = []\n",
    "AUPR = np.zeros(len(files))\n",
    "\n",
    "Rappel_d = {}\n",
    "Precision_d = {}\n",
    "a = {}\n",
    "\n",
    "for m in range (len(files)):\n",
    "    TP = []\n",
    "    TN = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    data = np.loadtxt(files[m])\n",
    "    seuils = np.unique(data[:,0])\n",
    "   \n",
    "    # On utilise la même méthode qu'à l'exercice 1 pour calculer notre matrice de confusion en peu de temps\n",
    "\n",
    "    for n in range (len(seuils)):   \n",
    "\n",
    "            TP = np.append(TP,np.sum((([data[:,0]>=seuils[n]]) & (data[:,1] == 1))*1))\n",
    "            FP = np.append(FP,np.sum((([data[:,0]>=seuils[n]]) & (data[:,1] == 0))*1))\n",
    "            TN = np.append(TN,np.sum((([data[:,0]<seuils[n]]) & (data[:,1] == 0))*1))\n",
    "            FN = np.append(FN,np.sum((([data[:,0]<seuils[n]]) & (data[:,1] == 1))*1))                \n",
    "    Recall = TP/(TP+FN)\n",
    "    Precision = TP/(FP+TP)\n",
    "    \n",
    "    for z in range (len(Recall)):\n",
    "        if (z<len(Recall)-1):\n",
    "            deltaR = Recall[z]-Recall[z+1]\n",
    "            deltaP = Precision[z]\n",
    "\n",
    "            AUPR[m] = AUPR[m] + deltaR*deltaP\n",
    "            \n",
    "            \n",
    "            Rappel_file = 'Fichier_'+str(m+1)\n",
    "            Rappel_seuil = 'Seuil_'+str(z)\n",
    "            Rappel_id = 'Rappel_fichier_'+str(m+1)+'_seuil_'+str(z)\n",
    "            \n",
    "            Rappel_d[Rappel_file] = m+1\n",
    "            Rappel_d[Rappel_seuil] = z\n",
    "            Rappel_d[Rappel_id] = Recall[z]\n",
    "\n",
    "            Precision_file = 'Fichier_'+str(m+1)\n",
    "            Precision_seuil = 'Seuil_'+str(z)\n",
    "            Precision_id = 'FPR_fichier_'+str(m+1)+'_seuil_'+str(z)\n",
    "            \n",
    "            Precision_d[Precision_file] = m+1\n",
    "            Precision_d[Precision_seuil] = z\n",
    "            Precision_d[Precision_id] = Precision[z]\n",
    "    \n",
    "    # On affiche nos courbe dans un graphique\n",
    "    \n",
    "    plt.plot(Recall, Precision,label=[round(AUPR[m],4),files[m][16:]])\n",
    "    plt.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "score = np.zeros(len(files))\n",
    "\n",
    "for y in range (len(files)):\n",
    "    data0 = np.loadtxt(files[y])\n",
    "\n",
    "    score[y] = average_precision_score(data0[:,1],data0[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La courbe Précision-Rappel est meilleure pour mesurer les performances car la matrice de confusion est débalancé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('lab1_1.npz')\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"x2\") \n",
    "\n",
    "data_x1_0 = []\n",
    "data_x2_0 = []\n",
    "data_x1_1 = []\n",
    "data_x2_1 = []\n",
    "\n",
    "# On sépare nos points de coordonnées en fonction de la valeur désirée\n",
    "\n",
    "for g in range (len(data['D'])):\n",
    "    if data['D'][g] == 0:\n",
    "        data_x1_0.append(data['X'][g,0])\n",
    "        data_x2_0.append(data['X'][g,1]) \n",
    "    else :\n",
    "        data_x1_1.append(data['X'][g,0])\n",
    "        data_x2_1.append(data['X'][g,1]) \n",
    "                \n",
    "plt.scatter(data_x1_0, data_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data_x1_1, data_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [0,-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"X2\") \n",
    "\n",
    "xmin = -1\n",
    "xmax = 4\n",
    "\n",
    "ymin = -8\n",
    "ymax = 6\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "x_frontiere = np.linspace(0, 10, num=11)\n",
    "\n",
    "plt.scatter(data_x1_0, data_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data_x1_1, data_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "\n",
    "# On affiche la frontière de décision initiale en fonction des poids initiaux\n",
    "\n",
    "plt.plot(x_frontiere, x_frontiere*(-w[1]/w[2])-(w[0]/w[2]),label='Frontière de décision', color='red', linestyle='--')\n",
    "plt.plot(np.linspace(xmin, xmax, num=11), np.linspace(0, 0, num=11), color='black')\n",
    "plt.plot(np.linspace(0, 0, num=11), np.linspace(ymin, ymax, num=11), color='black')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, lr: float):\n",
    "        \"\"\"\n",
    "        Constructeur de la classe Perceptron.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : float\n",
    "            Taux d'apprentissage pour la mise à jour des poids.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.w = np.array([0, -1, -1], dtype=np.float) # vecteur de poids   \n",
    "        self.lr = lr\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.float:\n",
    "        \"\"\"\n",
    "        Propagation directe du perceptron avec sa fonction d'activation $y = F(w^T x)$.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Vecteur d'entrée de longueur 2.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y : np.float\n",
    "            Sortie du perceptron après la fonction d'activation.\n",
    "        \n",
    "        \"\"\"\n",
    "        y = x[0]*self.w[1] + x[1]*self.w[2] + self.w[0]\n",
    "        y = 1/(1+math.exp(-y))\n",
    "        \n",
    "        return y\n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide\n",
    "    \n",
    "    def update(self, x: np.ndarray, grad_output: np.float) -> None:\n",
    "        \"\"\"\n",
    "        Mise à jour des poids w.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Vecteur d'entrée de longueur 2.\n",
    "        grad_output : np.float\n",
    "            Gradient de l'erreur par rapport à la sortie y perceptron $\\nabla_y E$. = (yi - di)\n",
    "\n",
    "        \"\"\"\n",
    "        self.w  = self.w - self.lr*grad_output*self.forward(x)*(1-self.forward(x))*np.insert(x,0,1,axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Perceptron(0.01)\n",
    "pred = np.zeros(len(data['X']))\n",
    "\n",
    "for v in range (len(data['X'])):\n",
    "    pred[v] = p.forward(data['X'][v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.zeros(len(pred))\n",
    "seuil = 0.5\n",
    "te = 0\n",
    "\n",
    "for h in range (len(pred)):\n",
    "    diff[h] = data['D'][h]-pred[h]\n",
    "    \n",
    "    # On considèrera un résultat de 0.5 comme un 1.\n",
    "    \n",
    "    if ((abs(diff[h])<=seuil)): \n",
    "        te+=1\n",
    "\n",
    "        \n",
    "te = te/len(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que la frontière de décision n'est pas correcte car selon celle-ci on predit correctement 7 données sur 8 or le taux calculé démontre que l'on prédit 1 donnée sur 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"X2\") \n",
    "\n",
    "x_frontiere = np.linspace(-10, 10, num=21)\n",
    "\n",
    "plt.scatter(data_x1_0, data_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data_x1_1, data_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "\n",
    "plt.plot(x_frontiere, x_frontiere*(-w[1]/w[2])-(w[0]/w[2]),label='Frontière de décision', color='red')\n",
    "plt.scatter(data['X'][:,1], data['X'][:,0]*w[1]+data['X'][:,1]*w[2]+w[0],label='Net',marker = 'p')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = np.zeros(len(data['X']))\n",
    "grad_output = np.zeros(len(data['X']))\n",
    "\n",
    "for v in range (len(data['X'])):\n",
    "    pred[v] = p.forward(data['X'][v])\n",
    "    grad_output[v] = pred[v]-data['D'][v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range (len(data['X'])):\n",
    "    p.update(data['X'][v],grad_output[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = np.zeros(100)\n",
    "diff = np.zeros(len(pred))\n",
    "seuil = 0.5\n",
    "erreur = np.zeros(100)\n",
    "\n",
    "p = Perceptron(0.01)\n",
    "\n",
    "#On effectue les 100 itérations de notre perceptron afin de mettre à jour les poids\n",
    "\n",
    "for i in range (100):\n",
    "    for v in range (len(data['X'])):\n",
    "        pred[v] = p.forward(data['X'][v]) # On calcul la valeur de sortie\n",
    "        grad_output[v] = pred[v]-data['D'][v] # Puis on calcul le gradient de notre sortie par rapport l'erreur\n",
    "        p.update(data['X'][v], grad_output[v]) # On met à jour nos poids en partant de ce gradient\n",
    "        diff[v] = data['D'][v]-pred[v]\n",
    "        \n",
    "        erreur[i] += ((grad_output[v])**2)*0.5 ##On calcul notre erreur et on fait la somme pour l'itération\n",
    "        \n",
    "    \n",
    "    # On considèrera un résultat de 0.5 comme un 1.\n",
    "    \n",
    "        if ((abs(diff[v])<=seuil)): \n",
    "            te[i]+=1\n",
    "    te[i] = te[i]/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche notre taux d'exactitude et notre erreur en fonction des itérations\n",
    "\n",
    "plt.xlabel(\"itérations\") \n",
    "plt.ylabel(\"Taux d'exactitude\") \n",
    "\n",
    "plt.plot(te,label='Te', color='red')\n",
    "plt.plot(erreur,label='Erreur', color='blue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche notre frontière de décision après les 100 itérations\n",
    "\n",
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"X2\") \n",
    "\n",
    "xmin = -1\n",
    "xmax = 4\n",
    "\n",
    "ymin = -8\n",
    "ymax = 6\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "x_frontiere = np.linspace(xmin, xmax, num=xmax-xmin+1)\n",
    "\n",
    "plt.scatter(data_x1_0, data_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data_x1_1, data_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "\n",
    "plt.plot(x_frontiere, x_frontiere*(-p.w[1]/p.w[2])-(p.w[0]/p.w[2]),label='Frontière de décision', color='red', linestyle='--')\n",
    "plt.plot(np.linspace(xmin, xmax, num=11), np.linspace(0, 0, num=11), color='black') #On affiche des axes pour plus de clarté\n",
    "plt.plot(np.linspace(0, 0, num=11), np.linspace(ymin, ymax, num=11), color='black')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au bout de 100 itérations, l'algorithme ne converge pas car nous n'arrivons pas à des poids constant et notre erreur diminue encore, les valeurs sont toujours en train d'évoluer. Nous n'obtenons pas à un taux d'exactitude de 100% ce qui confirme que nous n'avons pas convergé étant donné que notre problème est très simple, on sait que l'on doit avoir 100% à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On refait le calcul de avec plus d'itérations pour arriver à convergence\n",
    "\n",
    "epoch = 200\n",
    "\n",
    "te = np.zeros(epoch)\n",
    "diff = np.zeros(len(pred))\n",
    "seuil = 0.5\n",
    "erreur = np.zeros(epoch)\n",
    "\n",
    "p = Perceptron(0.01)\n",
    "\n",
    "for i in range (epoch):\n",
    "    for v in range (len(data['X'])):\n",
    "        pred[v] = p.forward(data['X'][v])\n",
    "        grad_output[v] = pred[v]-data['D'][v]\n",
    "        p.update(data['X'][v], grad_output[v])\n",
    "        diff[v] = data['D'][v]-pred[v]\n",
    "        erreur[i] += ((grad_output[v])**2)*0.5\n",
    "    \n",
    "    # On considèrera un résultat de 0.5 comme un 1.\n",
    "    \n",
    "        if ((abs(diff[v])<=seuil)): \n",
    "            te[i]+=1\n",
    "    te[i] = te[i]/len(pred)\n",
    "    \n",
    "plt.xlabel(\"itérations\") \n",
    "plt.ylabel(\"Taux d'exactitude\") \n",
    "plt.plot(erreur,label='Erreur', color='blue')\n",
    "plt.plot(te,label='Te', color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"X2\") \n",
    "\n",
    "xmin = -1\n",
    "xmax = 4\n",
    "\n",
    "ymin = -8\n",
    "ymax = 6\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "x_frontiere = np.linspace(xmin, xmax, num=xmax-xmin+1)\n",
    "\n",
    "plt.scatter(data_x1_0, data_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data_x1_1, data_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "\n",
    "plt.plot(x_frontiere, x_frontiere*(-p.w[1]/p.w[2])-(p.w[0]/p.w[2]),label='Frontière de décision', color='red', linestyle='--')\n",
    "plt.plot(np.linspace(xmin, xmax, num=11), np.linspace(0, 0, num=11), color='black')\n",
    "plt.plot(np.linspace(0, 0, num=11), np.linspace(ymin, ymax, num=11), color='black')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range (len(data['X'])):\n",
    "    pred[v] = p.forward(data['X'][v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on changeait l'ordre des données on finirai par obtenir les mêmes poids à la fin et on obtiendrai toujours la convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.load('lab1_2.npz')\n",
    "list(data2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"x2\") \n",
    "\n",
    "data2_x1_0 = []\n",
    "data2_x2_0 = []\n",
    "data2_x1_1 = []\n",
    "data2_x2_1 = []\n",
    "\n",
    "# Comme pour l'exercice précédent on sépare nos données en fonction de le valeur désirée\n",
    "\n",
    "for g in range (len(data2['D'])):\n",
    "    if data2['D'][g] == 0:\n",
    "        data2_x1_0.append(data2['X'][g,0])\n",
    "        data2_x2_0.append(data2['X'][g,1]) \n",
    "    else :\n",
    "        data2_x1_1.append(data2['X'][g,0])\n",
    "        data2_x2_1.append(data2['X'][g,1]) \n",
    "                \n",
    "plt.scatter(data2_x1_0, data2_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data2_x1_1, data2_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, n_in: int, n_out: int, lr: float):\n",
    "        \"\"\"\n",
    "        Constructeur de la classe Layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_int : int\n",
    "            Nombre d'entrées.\n",
    "        n_out : int\n",
    "            Nombre de sorties.\n",
    "        lr : float\n",
    "            Taux d'apprentissage pour la mise à jour des poids.\n",
    "        \n",
    "        \"\"\"\n",
    "        bound = (6 / (n_in + n_out)) ** 0.5  # initialisation selon Glorot & Bengio (2010)\n",
    "        # matrice de poids (+1 pour le biais)\n",
    "        self.W = np.random.uniform(low=-bound, high=bound, size=(n_out, n_in + 1)) \n",
    "        self.W[:, 0] = 0  # biais initialisé à 0\n",
    "        self.lr = lr # On initialise le taux d'apprentissage à celui en paramètre\n",
    "        self.n_in = n_in # même chose pour le nombre d'entrées et sorties\n",
    "        self.n_out = n_out\n",
    "        self.net = 0 # On initialise notre net à 0\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Propagation directe de la couche avec sa fonction d'activation $Y = F(W^T X)$.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées. Taille : (n_in, # exemples).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y : np.ndarray\n",
    "            Sorties de la couche après la fonction d'activation. Taille : (n_out, # exemples)\n",
    "\n",
    "        \"\"\"\n",
    "        y = np.zeros((len(X),self.n_out)) # On initialise y à un array de taille (n_out, # exemples)\n",
    "        self.X = X\n",
    "        X = np.insert(X,0,1,axis=1) # On insert des 1 dans la première colonne pour multiplier le biais directement avec\n",
    "        self.net = np.zeros((len(X),self.n_out))\n",
    "        for j in range (self.n_out):\n",
    "            for i in range(len(X)):\n",
    "                    self.net[i][j] = np.dot(X[i],self.W[j]) # On calcul notre net\n",
    "                    \n",
    "                    y[i][j] = sigmoid(self.net[i][j])       # et notre sortie avec la sigmoide comme fonction d'activation\n",
    "        return y\n",
    "        \n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide\n",
    "        \n",
    "    def update(self, X: np.ndarray, grad_output: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Mise à jour des poids w et retourne le gradient de l'erreur par rapport à l'entrée de la couche $\\nabla_X E$.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées. Taille : (n_in, # exemples).\n",
    "        grad_output : np.ndarray.\n",
    "            Gradient de l'erreur par rapport à la sortie Y de la couche $\\nabla_Y E$. Taille : (n_out, # exemples)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        grad_input : np.ndarray\n",
    "            Gradient de l'erreur par rapport à l'entrée X de la couche $\\nabla_X E$. Taille : (n_in, # exemples)\n",
    "\n",
    "        \"\"\"\n",
    "        grad_net = []     \n",
    "        grad_net = np.multiply(grad_output, (self.forward(X)*(1-self.forward(X)))) #On calcul notre grad_net en multipliant le\n",
    "                                                                                   #Gradient de l'erreur par rapport à la sortie\n",
    "                                                                                   #et le gradient local\n",
    "        grad_w = np.transpose(grad_net) @ np.insert(X,0,1,axis=1) # On calcul de la gradient de W avec un produit matriciel\n",
    "                                                                  # entre X et le grad_net\n",
    "        grad_input = grad_net @ np.delete(self.W, 0, 1) # Pour le gradient de l'erreur par rapport à l'entrée, on fait la même \n",
    "                                                        # Opération en remplaçant X par W (Poids)\n",
    "        self.W = self. W - self.lr*grad_w # On met à jour nos poids \n",
    "        \n",
    "        \n",
    "        return grad_input\n",
    "        \n",
    "        \n",
    "        pass  # pass ne fait rien et sert seulement à fournir syntaxe correcte pour une fonction vide\n",
    "\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "p = Layer(2,1,0.01)\n",
    "\n",
    "pred = p.forward(data2['X'])\n",
    "\n",
    "diff = np.zeros(len(pred))\n",
    "seuil = 0.5\n",
    "te = 0\n",
    "\n",
    "for h in range (len(pred)):\n",
    "    diff[h] = data2['D'][h]-pred[h]\n",
    "    \n",
    "    # On considèrera un résultat de 0.5 comme un 1.\n",
    "    \n",
    "    if ((abs(diff[h])<=seuil)): \n",
    "        te+=1\n",
    "\n",
    "        \n",
    "te = te/len(pred)\n",
    "\n",
    "print(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 300\n",
    "\n",
    "pred = []\n",
    "\n",
    "te = np.zeros(epoch)\n",
    "erreur = np.zeros(epoch)\n",
    "\n",
    "p = Layer(2,1,0.01)\n",
    "\n",
    "#pred = p.forward(data2['X'])\n",
    "\n",
    "diff = np.zeros(len(data2['D']))\n",
    "seuil = 0.5\n",
    "\n",
    "w_init = p.W\n",
    "\n",
    "# On effectue le calcul avec 300 itérations\n",
    "\n",
    "for i in range (epoch):\n",
    "    pred = p.forward(data2['X'])\n",
    "    grad_output = pred-data2['D']\n",
    "    p.update(data2['X'], grad_output)\n",
    "    erreur[i] += np.sum(((grad_output)**2))*0.5\n",
    "    for h in range (len(pred)):\n",
    "        diff[h] = data2['D'][h]-pred[h]\n",
    "    \n",
    "        # On considèrera un résultat de 0.5 comme un 1.\n",
    "    \n",
    "        \n",
    "        if ((abs(diff[h])<=seuil)): \n",
    "            te[i]+=1\n",
    "\n",
    "    te[i] = te[i]/len(pred)\n",
    "plt.xlabel(\"itérations\") \n",
    "plt.ylabel(\"Taux d'exactitude\") \n",
    "\n",
    "plt.plot(te,label='Te', color='red')\n",
    "plt.plot(erreur,label='Erreur', color='blue')\n",
    "plt.legend()\n",
    "\n",
    "#print(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"X2\") \n",
    "\n",
    "xmin = -1\n",
    "xmax = 4\n",
    "\n",
    "ymin = -8\n",
    "ymax = 6\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "x_frontiere = np.linspace(xmin, xmax, num=xmax-xmin+1)\n",
    "\n",
    "plt.scatter(data2_x1_0, data2_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data2_x1_1, data2_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "\n",
    "for i in range(p.n_out):\n",
    "    # On affiche la frontière de décision finale et initiale\n",
    "    plt.plot(x_frontiere, x_frontiere*(-p.W[i][1]/p.W[i][2])-(p.W[i][0]/p.W[i][2]),label='Frontière de décision finale', color='red', linestyle='--')\n",
    "    plt.plot(x_frontiere, x_frontiere*(-w_init[i][1]/w_init[i][2])-(w_init[i][0]/w_init[i][2]),label='Frontière de décision initiale', color='green', linestyle='--')\n",
    "    \n",
    "plt.plot(np.linspace(xmin, xmax, num=11), np.linspace(0, 0, num=11), color='black')\n",
    "plt.plot(np.linspace(0, 0, num=11), np.linspace(ymin, ymax, num=11), color='black')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme ne converge pas vraiment, notre erreur est encore assez élevé (0.6 contre presque 0 dans l'exercice 3) et notre taux d'exactitude n'atteint pas 100% non plus donc nos résultats ne sont pas très précis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous n'atteignons pas la convergence de ce problème, si nous changeons l'ordre des données, notre mise à jour des poids seraient différentes et nous aurions des poids différents à chaque executions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, list_of_layers: list):\n",
    "        \"\"\"\n",
    "        Classe pour implémenter un réseau de neurones multicouches.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        list_of_layers : list\n",
    "            Liste ordonnée des couches successives du réseau de neurones.\n",
    "        \"\"\"\n",
    "        self.list_of_layers = list_of_layers\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Propagation directe à travers les couches du MLP.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Y : np.ndarray\n",
    "            Sorties après propagation directe.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range (len(self.list_of_layers)):\n",
    "               \n",
    "            Y = self.list_of_layers[i].forward(X)\n",
    "            X = Y\n",
    "            \n",
    "        return Y\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def update(self, X: np.ndarray, grad_output: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Mise à jour des poids des couches successives du MLP. Renvoie le gradient de l'erreur par \n",
    "        rapport à l'entrée du MLP.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Données d'entrées.\n",
    "        grad_output : np.ndarray\n",
    "            Gradient de l'erreur par rapport à la sortie Y du MLP $\\nabla_Y E$.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        grad_input : np.ndarray\n",
    "            Gradient de l'erreur par rapport à l'entrée X de la couche $\\nabla_X E$.\n",
    "\n",
    "        \"\"\"\n",
    "        for i in range (len(self.list_of_layers)-1,-1,-1):\n",
    "\n",
    "            grad_input = self.list_of_layers[i].update(self.list_of_layers[i].X, grad_output)\n",
    "\n",
    "            grad_output = grad_input\n",
    "            \n",
    "        return grad_input\n",
    "        \n",
    "        pass\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "te = np.zeros(epoch)\n",
    "erreur = np.zeros(epoch)\n",
    "\n",
    "Layer_list = [Layer(2,3,lr),Layer(3,1,lr)] # On définis notre liste de layer\n",
    "\n",
    "mlp = MLP(Layer_list) # On crée notr MLP\n",
    "\n",
    "diff = np.zeros(len(data2['D']))\n",
    "seuil = 0.5\n",
    "\n",
    "for i in range (epoch):\n",
    "    pred = mlp.forward(data2['X'])\n",
    "    grad_output = pred-data2['D']\n",
    "    mlp.update(data2['X'], grad_output)\n",
    "    for h in range (len(pred)):\n",
    "        diff[h] = data2['D'][h]-pred[h]\n",
    "        \n",
    "        # On considèrera un résultat de 0.5 comme un 1.\n",
    "\n",
    "        if ((abs(diff[h])<=seuil)): \n",
    "            te[i]+=1\n",
    "        \n",
    "        erreur[i]+=(pred[h]-data2['D'][h])**2\n",
    "        \n",
    "    erreur[i]=0.5*erreur[i]    \n",
    "    te[i] = te[i]/len(pred)\n",
    "    \n",
    "plt.xlabel(\"itérations\") \n",
    "plt.ylabel(\"Taux d'exactitude\") \n",
    "\n",
    "# On affiche notre taux d'exactitude et notre erreur\n",
    "\n",
    "plt.plot(te,label='Te', color='red')\n",
    "plt.plot(erreur,label='Erreur', color='blue')\n",
    "plt.legend()\n",
    "\n",
    "print(Layer_list[0].W,Layer_list[1].W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester notre MLP, on regarde l'erreur pour décider des paramètres. Lorsque nous avons 2 couches et 2 neurones cachées nous obtenons les meilleurs résultats donc nous choisissons cette configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"X1\") \n",
    "plt.ylabel(\"X2\") \n",
    "\n",
    "xmin = -1\n",
    "xmax = 4\n",
    "\n",
    "ymin = -8\n",
    "ymax = 6\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "x_frontiere = np.linspace(xmin, xmax, num=xmax-xmin+1)\n",
    "\n",
    "\n",
    "plt.scatter(data2_x1_0, data2_x2_0,label='Valeur désirée à 0',marker = 'x')\n",
    "plt.scatter(data2_x1_1, data2_x2_1,label='Valeur désirée à 1',marker = '+')\n",
    "\n",
    "for k in range (len(Layer_list)):\n",
    "    for i in range(Layer_list[k].n_out):\n",
    "       \n",
    "\n",
    "        plt.plot(x_frontiere, x_frontiere*(-Layer_list[k].W[i][1]/Layer_list[k].W[i][2])-(Layer_list[k].W[i][0]/Layer_list[k].W[i][2]),label='FD Layer : ' + str(k+1) + ' Sortie : ' + str(i+1), linestyle='--')\n",
    "        \n",
    "plt.plot(np.linspace(xmin, xmax, num=11), np.linspace(0, 0, num=11), color='black')\n",
    "plt.plot(np.linspace(0, 0, num=11), np.linspace(ymin, ymax, num=11), color='black')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
